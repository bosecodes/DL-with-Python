{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GAN - MNISTic Implementation.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bosecodes/DL-with-Python/blob/master/GAN_MNISTic_Implementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0BryZPvZp4l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "eb77a72b-0d02-4d5f-9f73-f9e73f768b34"
      },
      "source": [
        "# Loading the MNIST dataset\n",
        "from keras.datasets.mnist import load_data\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = load_data()\n",
        "\n",
        "# Summarise the shape of the dataset\n",
        "print('Train : ', x_train.shape, y_train.shape)\n",
        "print('Test : ', x_test.shape, y_test.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train :  (60000, 28, 28) (60000,)\n",
            "Test :  (10000, 28, 28) (10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-sLxTbne6jh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hq5YJsBcfm9a",
        "colab_type": "text"
      },
      "source": [
        "# **Defining and Training the Discriminator model**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uwAHMaxCf_hK",
        "colab_type": "text"
      },
      "source": [
        "The first step is to define the Discriminator Model.\n",
        "The model must take a sample image from our dataset as input and output a classification prediction as to whether the sample is real or fake.\n",
        "\n",
        "This is a binary classification problem:\n",
        "\n",
        "- Inputs: Image with one channel and 28x28 in size\n",
        "- Output: Binary classification, 1 or 0, likelihood of the sample to be real or fake\n",
        "\n",
        "This Discriminator model has **2 convolutional layers with 64 filters each, a 3x3 kernel and a larger than normal stride of 2.** There are no Pooling layers and a single node output layer with the sigmoid activation function to predict whether the input sample is real or fake. The model is trained to minimize **binary cross entropy loss function**, which is appropriate for binary classification.\n",
        "\n",
        "We will use LeakyRELU (instead of RELU), Dropout, and Adam optimizer, with learning rate 0.0002 and momentum 0.5. This all is done as best practice.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pb2rmyTCe6sK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importing essential libraries\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, Flatten, Dropout, LeakyReLU\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils.vis_utils import plot_model\n",
        "\n",
        "#defining the standalone Discriminator model\n",
        "\n",
        "def define_discriminator(in_shape= (28,28,1)):\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(64, (3,3), strides = (2,2), padding = 'same', input_shape = in_shape))\n",
        "  model.add(LeakyRELU(alpha = 0.2))\n",
        "  model.add(Dropout(0.4))\n",
        "  model.add(Conv2D(64, (3,3), strides = (2,2), padding = 'same'))\n",
        "  model.add(LeakyRELU(alpha = 0.2))\n",
        "  model.add(Dropout(0.4))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(1, activation = 'sigmoid'))\n",
        "\n",
        "  # compile the model\n",
        "  opt = Adam(lr = 0.0002, beta_1 = 0.5)\n",
        "  model.compile(loss = 'binary_crossentropy', optimizer = opt, metrics = ['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1X7QbRJYe60g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "b4554b06-146f-4c2d-c372-16bb852cef36"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(x_train[0], cmap = 'gray_r')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f5a68ea77b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAOUElEQVR4nO3dX4xUdZrG8ecF8R+DCkuHtAyRGTQm\nHY1AStgEg+hk8U+iwI2BGERjxAuQmQTiolzAhRdGd2YyihnTqAE2IxPCSITErIMEY4iJoVC2BZVF\nTeNA+FOE6Dh6gTLvXvRh0mLXr5qqU3XKfr+fpNPV56nT502Fh1Ndp7t+5u4CMPQNK3oAAK1B2YEg\nKDsQBGUHgqDsQBAXtfJgY8eO9YkTJ7bykEAovb29OnXqlA2UNVR2M7tT0h8kDZf0krs/nbr/xIkT\nVS6XGzkkgIRSqVQ1q/tpvJkNl/SCpLskdUlaYGZd9X4/AM3VyM/s0yR96u6fu/sZSX+WNCefsQDk\nrZGyj5f0t35fH8m2/YCZLTazspmVK5VKA4cD0Iimvxrv7t3uXnL3UkdHR7MPB6CKRsp+VNKEfl//\nPNsGoA01UvY9kq4zs1+Y2cWS5kvals9YAPJW96U3d//ezJZKelN9l95ecfcDuU0GIFcNXWd39zck\nvZHTLACaiF+XBYKg7EAQlB0IgrIDQVB2IAjKDgRB2YEgKDsQBGUHgqDsQBCUHQiCsgNBUHYgCMoO\nBEHZgSAoOxAEZQeCoOxAEJQdCIKyA0FQdiAIyg4EQdmBICg7EARlB4Kg7EAQlB0IgrIDQVB2IIiG\nVnFF+zt79mwy/+qrr5p6/LVr11bNvv322+S+Bw8eTOYvvPBCMl+xYkXVbNOmTcl9L7300mS+cuXK\nZL569epkXoSGym5mvZK+lnRW0vfuXspjKAD5y+PMfpu7n8rh+wBoIn5mB4JotOwu6a9mttfMFg90\nBzNbbGZlMytXKpUGDwegXo2W/RZ3nyrpLklLzGzm+Xdw9253L7l7qaOjo8HDAahXQ2V396PZ55OS\ntkqalsdQAPJXd9nNbKSZjTp3W9JsSfvzGgxAvhp5NX6cpK1mdu77vOru/5PLVEPMF198kczPnDmT\nzN99991kvnv37qrZl19+mdx3y5YtybxIEyZMSOaPPfZYMt+6dWvVbNSoUcl9b7rppmR+6623JvN2\nVHfZ3f1zSelHBEDb4NIbEARlB4Kg7EAQlB0IgrIDQfAnrjn44IMPkvntt9+ezJv9Z6btavjw4cn8\nqaeeSuYjR45M5vfff3/V7Oqrr07uO3r06GR+/fXXJ/N2xJkdCIKyA0FQdiAIyg4EQdmBICg7EARl\nB4LgOnsOrrnmmmQ+duzYZN7O19mnT5+ezGtdj961a1fV7OKLL07uu3DhwmSOC8OZHQiCsgNBUHYg\nCMoOBEHZgSAoOxAEZQeC4Dp7DsaMGZPMn3322WS+ffv2ZD5lypRkvmzZsmSeMnny5GT+1ltvJfNa\nf1O+f3/1pQSee+655L7IF2d2IAjKDgRB2YEgKDsQBGUHgqDsQBCUHQiC6+wtMHfu3GRe633lay0v\n3NPTUzV76aWXkvuuWLEimde6jl7LDTfcUDXr7u5u6HvjwtQ8s5vZK2Z20sz299s2xsx2mNmh7HP6\nHQwAFG4wT+PXS7rzvG0rJe109+sk7cy+BtDGapbd3d+RdPq8zXMkbchub5CUfp4KoHD1vkA3zt2P\nZbePSxpX7Y5mttjMymZWrlQqdR4OQKMafjXe3V2SJ/Judy+5e6mjo6PRwwGoU71lP2FmnZKUfT6Z\n30gAmqHesm+TtCi7vUjS6/mMA6BZal5nN7NNkmZJGmtmRyStlvS0pM1m9rCkw5Lua+aQQ90VV1zR\n0P5XXnll3fvWug4/f/78ZD5sGL+X9VNRs+zuvqBK9KucZwHQRPy3DARB2YEgKDsQBGUHgqDsQBD8\niesQsGbNmqrZ3r17k/u+/fbbybzWW0nPnj07maN9cGYHgqDsQBCUHQiCsgNBUHYgCMoOBEHZgSC4\nzj4EpN7ued26dcl9p06dmswfeeSRZH7bbbcl81KpVDVbsmRJcl8zS+a4MJzZgSAoOxAEZQeCoOxA\nEJQdCIKyA0FQdiAIrrMPcZMmTUrm69evT+YPPfRQMt+4cWPd+TfffJPc94EHHkjmnZ2dyRw/xJkd\nCIKyA0FQdiAIyg4EQdmBICg7EARlB4LgOntw8+bNS+bXXnttMl++fHkyT73v/BNPPJHc9/Dhw8l8\n1apVyXz8+PHJPJqaZ3Yze8XMTprZ/n7b1pjZUTPbl33c3dwxATRqME/j10u6c4Dtv3f3ydnHG/mO\nBSBvNcvu7u9IOt2CWQA0USMv0C01s57saf7oancys8VmVjazcqVSaeBwABpRb9n/KGmSpMmSjkn6\nbbU7unu3u5fcvdTR0VHn4QA0qq6yu/sJdz/r7v+UtE7StHzHApC3uspuZv3/tnCepP3V7gugPdS8\nzm5mmyTNkjTWzI5IWi1plplNluSSeiU92sQZUaAbb7wxmW/evDmZb9++vWr24IMPJvd98cUXk/mh\nQ4eS+Y4dO5J5NDXL7u4LBtj8chNmAdBE/LosEARlB4Kg7EAQlB0IgrIDQZi7t+xgpVLJy+Vyy46H\n9nbJJZck8++++y6ZjxgxIpm/+eabVbNZs2Yl9/2pKpVKKpfLA651zZkdCIKyA0FQdiAIyg4EQdmB\nICg7EARlB4LgraSR1NPTk8y3bNmSzPfs2VM1q3UdvZaurq5kPnPmzIa+/1DDmR0IgrIDQVB2IAjK\nDgRB2YEgKDsQBGUHguA6+xB38ODBZP78888n89deey2ZHz9+/IJnGqyLLkr/8+zs7Ezmw4ZxLuuP\nRwMIgrIDQVB2IAjKDgRB2YEgKDsQBGUHguA6+09ArWvZr776atVs7dq1yX17e3vrGSkXN998czJf\ntWpVMr/33nvzHGfIq3lmN7MJZrbLzD4yswNm9uts+xgz22Fmh7LPo5s/LoB6DeZp/PeSlrt7l6R/\nl7TEzLokrZS0092vk7Qz+xpAm6pZdnc/5u7vZ7e/lvSxpPGS5kjakN1tg6S5zRoSQOMu6AU6M5so\naYqk9ySNc/djWXRc0rgq+yw2s7KZlSuVSgOjAmjEoMtuZj+T9BdJv3H3v/fPvG91yAFXiHT3bncv\nuXupo6OjoWEB1G9QZTezEeor+p/c/dyfQZ0ws84s75R0sjkjAshDzUtvZmaSXpb0sbv/rl+0TdIi\nSU9nn19vyoRDwIkTJ5L5gQMHkvnSpUuT+SeffHLBM+Vl+vTpyfzxxx+vms2ZMye5L3+imq/BXGef\nIWmhpA/NbF+27Un1lXyzmT0s6bCk+5ozIoA81Cy7u++WNODi7pJ+le84AJqF50lAEJQdCIKyA0FQ\ndiAIyg4EwZ+4DtLp06erZo8++mhy33379iXzzz77rK6Z8jBjxoxkvnz58mR+xx13JPPLLrvsgmdC\nc3BmB4Kg7EAQlB0IgrIDQVB2IAjKDgRB2YEgwlxnf++995L5M888k8z37NlTNTty5EhdM+Xl8ssv\nr5otW7YsuW+tt2seOXJkXTOh/XBmB4Kg7EAQlB0IgrIDQVB2IAjKDgRB2YEgwlxn37p1a0N5I7q6\nupL5Pffck8yHDx+ezFesWFE1u+qqq5L7Ig7O7EAQlB0IgrIDQVB2IAjKDgRB2YEgKDsQhLl7+g5m\nEyRtlDROkkvqdvc/mNkaSY9IqmR3fdLd30h9r1Kp5OVyueGhAQysVCqpXC4PuOryYH6p5ntJy939\nfTMbJWmvme3Ist+7+3/lNSiA5hnM+uzHJB3Lbn9tZh9LGt/swQDk64J+ZjeziZKmSDr3Hk9LzazH\nzF4xs9FV9llsZmUzK1cqlYHuAqAFBl12M/uZpL9I+o27/13SHyVNkjRZfWf+3w60n7t3u3vJ3Usd\nHR05jAygHoMqu5mNUF/R/+Tur0mSu59w97Pu/k9J6yRNa96YABpVs+xmZpJelvSxu/+u3/bOfneb\nJ2l//uMByMtgXo2fIWmhpA/N7Nzaw09KWmBmk9V3Oa5XUnrdYgCFGsyr8bslDXTdLnlNHUB74Tfo\ngCAoOxAEZQeCoOxAEJQdCIKyA0FQdiAIyg4EQdmBICg7EARlB4Kg7EAQlB0IgrIDQdR8K+lcD2ZW\nkXS436axkk61bIAL066ztetcErPVK8/ZrnH3Ad//raVl/9HBzcruXipsgIR2na1d55KYrV6tmo2n\n8UAQlB0Iouiydxd8/JR2na1d55KYrV4tma3Qn9kBtE7RZ3YALULZgSAKKbuZ3WlmB83sUzNbWcQM\n1ZhZr5l9aGb7zKzQ9aWzNfROmtn+ftvGmNkOMzuUfR5wjb2CZltjZkezx26fmd1d0GwTzGyXmX1k\nZgfM7NfZ9kIfu8RcLXncWv4zu5kNl/R/kv5D0hFJeyQtcPePWjpIFWbWK6nk7oX/AoaZzZT0D0kb\n3f2GbNszkk67+9PZf5Sj3f0/22S2NZL+UfQy3tlqRZ39lxmXNFfSgyrwsUvMdZ9a8LgVcWafJulT\nd//c3c9I+rOkOQXM0fbc/R1Jp8/bPEfShuz2BvX9Y2m5KrO1BXc/5u7vZ7e/lnRumfFCH7vEXC1R\nRNnHS/pbv6+PqL3We3dJfzWzvWa2uOhhBjDO3Y9lt49LGlfkMAOouYx3K523zHjbPHb1LH/eKF6g\n+7Fb3H2qpLskLcmerrYl7/sZrJ2unQ5qGe9WGWCZ8X8p8rGrd/nzRhVR9qOSJvT7+ufZtrbg7kez\nzyclbVX7LUV94twKutnnkwXP8y/ttIz3QMuMqw0euyKXPy+i7HskXWdmvzCziyXNl7StgDl+xMxG\nZi+cyMxGSpqt9luKepukRdntRZJeL3CWH2iXZbyrLTOugh+7wpc/d/eWf0i6W32vyH8maVURM1SZ\n65eS/jf7OFD0bJI2qe9p3Xfqe23jYUn/JmmnpEOS3pI0po1m+29JH0rqUV+xOgua7Rb1PUXvkbQv\n+7i76McuMVdLHjd+XRYIghfogCAoOxAEZQeCoOxAEJQdCIKyA0FQdiCI/wfvpjt5Q0mdXQAAAABJ\nRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cASxAUV_e63d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "e915d637-9502-41d3-ebdc-1a192d4df017"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 26, 26, 64)        640       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 24, 24, 64)        36928     \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 36864)             0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                368650    \n",
            "=================================================================\n",
            "Total params: 406,218\n",
            "Trainable params: 406,218\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DsucOjie68u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The images are 2d arrays of pixels and CNNs expect 3d arrays of images as input\n",
        "# X = expand_dims(x_train, axis = -1)\n",
        "\n",
        "# X = X.astype('float32')\n",
        "# X /= 255\n",
        "\n",
        "# The below function does exactly that"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atKUAkA5e6_S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_real_samples():\n",
        "  # load mnist dataset\n",
        "  (x_train, _), (_, _) = load_data()\n",
        "  # Expand to 3d, add channel dimensions\n",
        "  X = expand_dims(x_train, axis = -1)\n",
        "  X = X.astype('float32')\n",
        "  X /= 255\n",
        "  return X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pbLDN1hmWD5",
        "colab_type": "text"
      },
      "source": [
        "The model will be updated in batches, specifically with a collection of generated samples.\n",
        "\n",
        "Good training through a definite epoch is possible via Stochastic Gradient Descent, and that requires the training dataset to be shuffled prior to each epoch. A simpler approach would be to select random samples of images from the training dataset.\n",
        "\n",
        "The following function will take the training dataset as the argument and will select a random subsample of images, it will also return class labels for the sample, specifically a class label of 1, to indicate real images.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IuOiMQVJe7e4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "\n",
        "# select real samples\n",
        "\n",
        "def generate_real_samples(dataset, n_samples):\n",
        "  # choose random instances\n",
        "  ix = random.randint(0, dataset.shape[0], n_samples)\n",
        "  # retrieve the selected images\n",
        "  X = dataset[ix]\n",
        "  # generate the 'real' class labels(1)\n",
        "  y = ones((n_samples, 1))\n",
        "  return X,y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sbhkZZkznm-2",
        "colab_type": "text"
      },
      "source": [
        "Now, we need a source of fake images. \n",
        "Since we don't have a generator model yet, we can generate images comprised of random ixel values and their associated class label would be 0, for fake.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SrWVEh_6e7hd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "\n",
        "# generate n fake samples with class labels\n",
        "def generate_fake_samples(n_samples):\n",
        "  X = random.rand(28*28*n_samples)\n",
        "  # reshape into a batch of grayscale images\n",
        "  X = X.reshape((n_samples, 28, 28, 1))\n",
        "  # generate 'fake' class labels (0)\n",
        "  y = zeros((n_samples, 1))\n",
        "  return X,y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hzhj14tLoei7",
        "colab_type": "text"
      },
      "source": [
        "# Finally we train the discriminator model\n",
        "\n",
        "This involves repeatedly retrieving samples of real images and samples of fake images and updating the model for a fixed number of iterations.\n",
        "\n",
        "We will skip the idea of epochs now (eg, complete passes through the training dataset), and fit the discriminator model for a fixed number of batches. The model will learn to discriminate between real and fake images(randomly generated) rapidly, and therefore not many batches will be required before it discriminates perfectly.\n",
        "\n",
        "The following function does exactly this, we are using a batch size of 256 images where 128 are real, 128 are fake for each iteration.\n",
        "\n",
        "We update the discriminator model seperately for real and fake examples so that we can calculate the accuracy of the model on each sample prior to the update. This gives insight into how the discriminator model is performing over time.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rArR6lvUe7kF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train the discriminator model\n",
        "def train_discriminator(model, dataset, n_iter = 100, n_batch = 256):\n",
        "  half_batch = int(n_batch/2)\n",
        "  # manually enumerate epochs\n",
        "  for i in range(n_iter):\n",
        "    # get randomly selected 'real' samples\n",
        "    X_real, y_real = generate_real_samples(dataset, half_batch)\n",
        "    #f update discriminator on real samples\n",
        "    _, real_acc = model.train_on_batch(X_real, y_real)\n",
        "    # get randomly selected 'fake' samples\n",
        "    X_fake, y_fake = generate_fake_samples(half_batch)\n",
        "    # update discriminator on fake samples\n",
        "    _, fake_acc = model.train_on_batch(X_fake, y_fake)\n",
        "    # summarize performance\n",
        "    print('>%d real= %.0f%% fake=%.0f%%' %(i+1, real_acc*100, fake_acc*100))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWe62Q6_qwVa",
        "colab_type": "text"
      },
      "source": [
        "Tying all of this together, the complete example of training an instance of the discriminator model on real and randomly generated (fake) images is listed below.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Psp2mZVle7m4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9b525d02-6a51-4f54-83ee-86ffe546ca3d"
      },
      "source": [
        "# example of training the discriminator model on real and random mnist images\n",
        "\n",
        "#import the necessary packages\n",
        "from numpy import expand_dims\n",
        "from numpy import ones\n",
        "from numpy import zeros\n",
        "from numpy.random import rand\n",
        "from numpy.random import randint\n",
        "from keras.datasets.mnist import load_data\n",
        "from keras.optimizers import Adam\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LeakyReLU\n",
        " \n",
        "# define the standalone discriminator model\n",
        "def define_discriminator(in_shape=(28,28,1)):\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Conv2D(64, (3,3), strides=(2, 2), padding='same', input_shape=in_shape))\n",
        "\tmodel.add(LeakyReLU(alpha=0.2))\n",
        "\tmodel.add(Dropout(0.4))\n",
        "\tmodel.add(Conv2D(64, (3,3), strides=(2, 2), padding='same'))\n",
        "\tmodel.add(LeakyReLU(alpha=0.2))\n",
        "\tmodel.add(Dropout(0.4))\n",
        "\tmodel.add(Flatten())\n",
        "\tmodel.add(Dense(1, activation='sigmoid'))\n",
        "\t# compile model\n",
        "\topt = Adam(lr=0.0002, beta_1=0.5)\n",
        "\tmodel.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "\treturn model\n",
        " \n",
        "# load and prepare mnist training images\n",
        "def load_real_samples():\n",
        "\t# load mnist dataset\n",
        "\t(trainX, _), (_, _) = load_data()\n",
        "\t# expand to 3d, e.g. add channels dimension\n",
        "\tX = expand_dims(trainX, axis=-1)\n",
        "\t# convert from unsigned ints to floats\n",
        "\tX = X.astype('float32')\n",
        "\t# scale from [0,255] to [0,1]\n",
        "\tX = X / 255.0\n",
        "\treturn X\n",
        " \n",
        "# select real samples\n",
        "def generate_real_samples(dataset, n_samples):\n",
        "\t# choose random instances\n",
        "\tix = randint(0, dataset.shape[0], n_samples)\n",
        "\t# retrieve selected images\n",
        "\tX = dataset[ix]\n",
        "\t# generate 'real' class labels (1)\n",
        "\ty = ones((n_samples, 1))\n",
        "\treturn X, y\n",
        " \n",
        "# generate n fake samples with class labels\n",
        "def generate_fake_samples(n_samples):\n",
        "\t# generate uniform random numbers in [0,1]\n",
        "\tX = rand(28 * 28 * n_samples)\n",
        "\t# reshape into a batch of grayscale images\n",
        "\tX = X.reshape((n_samples, 28, 28, 1))\n",
        "\t# generate 'fake' class labels (0)\n",
        "\ty = zeros((n_samples, 1))\n",
        "\treturn X, y\n",
        " \n",
        "# train the discriminator model\n",
        "def train_discriminator(model, dataset, n_iter=100, n_batch=256):\n",
        "\thalf_batch = int(n_batch / 2)\n",
        "\t# manually enumerate epochs\n",
        "\tfor i in range(n_iter):\n",
        "\t\t# get randomly selected 'real' samples\n",
        "\t\tX_real, y_real = generate_real_samples(dataset, half_batch)\n",
        "\t\t# update discriminator on real samples\n",
        "\t\t_, real_acc = model.train_on_batch(X_real, y_real)\n",
        "\t\t# generate 'fake' examples\n",
        "\t\tX_fake, y_fake = generate_fake_samples(half_batch)\n",
        "\t\t# update discriminator on fake samples\n",
        "\t\t_, fake_acc = model.train_on_batch(X_fake, y_fake)\n",
        "\t\t# summarize performance\n",
        "\t\tprint('>%d real=%.0f%% fake=%.0f%%' % (i+1, real_acc*100, fake_acc*100))\n",
        " \n",
        "# define the discriminator model\n",
        "model = define_discriminator()\n",
        "# load image data\n",
        "dataset = load_real_samples()\n",
        "# fit the model\n",
        "train_discriminator(model, dataset)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            ">1 real=45% fake=17%\n",
            ">2 real=70% fake=23%\n",
            ">3 real=64% fake=47%\n",
            ">4 real=56% fake=60%\n",
            ">5 real=50% fake=80%\n",
            ">6 real=61% fake=91%\n",
            ">7 real=56% fake=97%\n",
            ">8 real=66% fake=100%\n",
            ">9 real=52% fake=100%\n",
            ">10 real=60% fake=100%\n",
            ">11 real=58% fake=100%\n",
            ">12 real=61% fake=100%\n",
            ">13 real=59% fake=100%\n",
            ">14 real=59% fake=100%\n",
            ">15 real=64% fake=100%\n",
            ">16 real=62% fake=100%\n",
            ">17 real=65% fake=100%\n",
            ">18 real=65% fake=100%\n",
            ">19 real=63% fake=100%\n",
            ">20 real=70% fake=100%\n",
            ">21 real=76% fake=100%\n",
            ">22 real=81% fake=100%\n",
            ">23 real=80% fake=100%\n",
            ">24 real=82% fake=100%\n",
            ">25 real=89% fake=100%\n",
            ">26 real=94% fake=100%\n",
            ">27 real=93% fake=100%\n",
            ">28 real=90% fake=100%\n",
            ">29 real=95% fake=100%\n",
            ">30 real=97% fake=100%\n",
            ">31 real=98% fake=100%\n",
            ">32 real=99% fake=100%\n",
            ">33 real=99% fake=100%\n",
            ">34 real=99% fake=100%\n",
            ">35 real=99% fake=100%\n",
            ">36 real=99% fake=100%\n",
            ">37 real=98% fake=100%\n",
            ">38 real=100% fake=100%\n",
            ">39 real=100% fake=100%\n",
            ">40 real=100% fake=100%\n",
            ">41 real=100% fake=100%\n",
            ">42 real=100% fake=100%\n",
            ">43 real=100% fake=100%\n",
            ">44 real=100% fake=100%\n",
            ">45 real=100% fake=100%\n",
            ">46 real=100% fake=100%\n",
            ">47 real=100% fake=100%\n",
            ">48 real=100% fake=100%\n",
            ">49 real=100% fake=100%\n",
            ">50 real=100% fake=100%\n",
            ">51 real=100% fake=100%\n",
            ">52 real=100% fake=100%\n",
            ">53 real=100% fake=100%\n",
            ">54 real=100% fake=100%\n",
            ">55 real=100% fake=100%\n",
            ">56 real=100% fake=100%\n",
            ">57 real=100% fake=100%\n",
            ">58 real=100% fake=100%\n",
            ">59 real=100% fake=100%\n",
            ">60 real=100% fake=100%\n",
            ">61 real=100% fake=100%\n",
            ">62 real=100% fake=100%\n",
            ">63 real=100% fake=100%\n",
            ">64 real=100% fake=100%\n",
            ">65 real=100% fake=100%\n",
            ">66 real=100% fake=100%\n",
            ">67 real=100% fake=100%\n",
            ">68 real=100% fake=100%\n",
            ">69 real=100% fake=100%\n",
            ">70 real=100% fake=100%\n",
            ">71 real=100% fake=100%\n",
            ">72 real=100% fake=100%\n",
            ">73 real=100% fake=100%\n",
            ">74 real=100% fake=100%\n",
            ">75 real=100% fake=100%\n",
            ">76 real=100% fake=100%\n",
            ">77 real=100% fake=100%\n",
            ">78 real=100% fake=100%\n",
            ">79 real=100% fake=100%\n",
            ">80 real=100% fake=100%\n",
            ">81 real=100% fake=100%\n",
            ">82 real=100% fake=100%\n",
            ">83 real=100% fake=100%\n",
            ">84 real=100% fake=100%\n",
            ">85 real=100% fake=100%\n",
            ">86 real=100% fake=100%\n",
            ">87 real=100% fake=100%\n",
            ">88 real=100% fake=100%\n",
            ">89 real=100% fake=100%\n",
            ">90 real=100% fake=100%\n",
            ">91 real=100% fake=100%\n",
            ">92 real=100% fake=100%\n",
            ">93 real=100% fake=100%\n",
            ">94 real=100% fake=100%\n",
            ">95 real=100% fake=100%\n",
            ">96 real=100% fake=100%\n",
            ">97 real=100% fake=100%\n",
            ">98 real=100% fake=100%\n",
            ">99 real=100% fake=100%\n",
            ">100 real=100% fake=100%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilNI6FkwrNUK",
        "colab_type": "text"
      },
      "source": [
        "Running the above snippet \n",
        "- Step 1: Defines the model\n",
        "- Step 2: Loads the MNIST Dataset\n",
        "- Step 3: Trains the discriminator model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2J0kf-Grqm7",
        "colab_type": "text"
      },
      "source": [
        "In our case the discriminator model learns to tell the difference between real and fake(random pixel generated) MNIST images very quickly, in about 38 batches.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W42wFd_nrHEb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjqxcdnErHHe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mrXiwaTErHJC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04CON6tIrHNN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DUV8JT0rHRe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIsFK7WJrHTw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CY6FGPXxrHXl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKelEnkbrHZU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XsPEiecVrHdn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7BhAlfcrHfr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDaih555rHjp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_vdzm1DrHoc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}